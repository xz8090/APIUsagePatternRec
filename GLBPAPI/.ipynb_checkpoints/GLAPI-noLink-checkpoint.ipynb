{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle as pk\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator,GraphSAGELinkGenerator\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.layer import GraphSAGE, HinSAGE, link_classification\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "\n",
    "from stellargraph import globalvar\n",
    "from stellargraph import datasets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "\n",
    "datasetname = 'TEST'#有数据集SH_S、SH_L、MV\n",
    "threshold1 = 0.5\n",
    "threshold2 = 0.5\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_samples = [20, 10]\n",
    "layer_sizes = [64, 64]\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "logging.basicConfig(format='%(asctime)s-%(levelname)s:%(message)s',\n",
    "                    filename='./log/new_noLink_'+datasetname+'_'+'_'+now+'.log',\n",
    "                    filemode='a', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "best_suc = [0]*21\n",
    "best_pre = [0]*21\n",
    "best_recall = [0]*21\n",
    "pro_best_suc = [0]*21\n",
    "pro_best_pre = [0]*21\n",
    "pro_best_recall = [0]*21\n",
    "test_config = 'C2.1'\n",
    "\n",
    "def getg(data):\n",
    "    g = nx.Graph()\n",
    "    n = len(data.item_method_id)\n",
    "    # 顶点\n",
    "    point = []\n",
    "    for i in range(n):\n",
    "        point.append(i)\n",
    "    g.add_nodes_from(point)\n",
    "    # 边权重\n",
    "    edglist = []\n",
    "    edges = set()\n",
    "    for user, items in tqdm(data.invocation_mx.items()):\n",
    "        for i in range(len(items)):\n",
    "            for j in range(i+1,len(items)):\n",
    "                edges.add((items[i],items[j]))\n",
    "    \n",
    "    for edg in tqdm(edges):\n",
    "        edglist.append((edg[0],edg[1],float(data.adj[edg[0],edg[1]])))\n",
    "        #edglist.append((edg[0],edg[1]))\n",
    "\n",
    "    g.add_weighted_edges_from(edglist)\n",
    "    #g.add_edges_from(edglist)\n",
    "    return g\n",
    "\n",
    "def to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def build_my_new_adj_matrix(data,train_dict):\n",
    "    n = len(data.item_method_id)\n",
    "    A = sp.dok_matrix((n, n), dtype=np.float32)\n",
    "    FD = defaultdict(int)\n",
    "    for user, items in tqdm(train_dict.items()):\n",
    "        for i in range(len(items)):\n",
    "            FD[items[i]] += 1\n",
    "            for j in range(i+1,len(items)):\n",
    "                if A[items[i],items[j]] == 0:\n",
    "                    A[items[i],items[j]] = A[items[j],items[i]] = len(data.invocation_mx.items())\n",
    "                else:\n",
    "                    A[items[i], items[j]] = A[items[j], items[i]] = A[items[j], items[i]] + len(data.invocation_mx.items())\n",
    "    print('build_my_new_adj_matrix finish')\n",
    "    data.FD = FD\n",
    "    data.adj = to_torch_sparse_tensor(A)\n",
    "    \n",
    "\n",
    "def load_mydata(dataset_name):\n",
    "    name = './tmp/%s-mydata.pk' % dataset_name\n",
    "    if not os.path.exists(name):\n",
    "        print('no file.')\n",
    "    with open(name, 'rb') as f:\n",
    "        data = pk.load(f)\n",
    "        print('load dataset from disk.')\n",
    "    #data.adj = to_torch_sparse_tensor(data.adj)\n",
    "    return data\n",
    "\n",
    "#threshold1取值（0，1）表示考虑节点相似特征的阈值，值越大候选特征节点越少\n",
    "#threshold2取值（0，1）表示节点属性特征的重要性，越小越不重要\n",
    "def build_new_relation(ratings,threshold1 = 0.8,threshold2 = 0.001):\n",
    "    dataset = load_mydata(datasetname)\n",
    "    n = len(ratings)\n",
    "    for i in tqdm(range(n)):\n",
    "        for j in range(i+1,n):\n",
    "            simily = float(ratings[i][j])\n",
    "            if simily >= threshold1:\n",
    "                if dataset.adj[i,j] == 0:\n",
    "                    dataset.adj[i,j] = threshold2*simily\n",
    "    return dataset\n",
    "    \n",
    "def get_my_top_items(tensor):\n",
    "    item_dict = {}\n",
    "    for i in tqdm(range(len(tensor))):\n",
    "        if tensor[i].item() !=0 :\n",
    "            item_dict[i] = tensor[i].item()\n",
    "    #print('get_my_top_items==>item_dict',item_dict)\n",
    "    top_items = [item[0] for item in sorted(item_dict.items(),key=lambda item:item[1],reverse=True)]\n",
    "    #print('get_my_top_items==>top_items',top_items)\n",
    "    return top_items[:21]\n",
    "\n",
    "def get_my_top_items2(data,adj,Q):\n",
    "    M = len(data.invocation_mx.items())\n",
    "    D = set()\n",
    "    FD = data.FD\n",
    "    \n",
    "    for q in Q:\n",
    "        tensor = adj[q]\n",
    "        for i in range(len(tensor)):\n",
    "            if tensor[i].item() != 0:\n",
    "                D.add(i)\n",
    "                \n",
    "    item_dict = {}\n",
    "    for d in D:\n",
    "        fd = FD[d]\n",
    "        fdq = 1\n",
    "        for q in Q:\n",
    "            tensor = adj[q]\n",
    "            fdq = fdq*(tensor[d].item()*1.0/fd)\n",
    "        item_dict[d] = fdq*fd*1.0/M\n",
    "\n",
    "    top_items = [item[0] for item in sorted(item_dict.items(), key=lambda item: item[1], reverse=True)]\n",
    "    # print('get_my_top_items==>top_items',top_items)\n",
    "    return top_items[:21]\n",
    "\n",
    "def myeval(dataset):\n",
    "    test_set = dataset.test_dict\n",
    "    logger.info('test start. test set size: %d' % len(test_set))\n",
    "    t1 = time.time()\n",
    "    users = np.asarray(list(test_set.keys()))  # 训练集的方法编号数组\n",
    "\n",
    "    top_items = []\n",
    "    used_items = []\n",
    "\n",
    "    for userid in tqdm(users):\n",
    "        used_items.append(set(dataset.train_dict[userid]))\n",
    "        #print(dataset.train_dict[userid],dataset.train_dict[userid][0])\n",
    "        #top_items.append(get_my_top_items(dataset.adj[dataset.train_dict[userid][0]]))\n",
    "        top_items.append(get_my_top_items2(dataset,dataset.adj,dataset.train_dict[userid]))\n",
    "\n",
    "    #print('myeval2=>top_items',top_items)\n",
    "    #print('myeval2=>used_items', used_items)\n",
    "\n",
    "    items = []\n",
    "    for i, item in enumerate(top_items):  # 第i个测试方法推荐的API列表item\n",
    "        logger.info('context:%s;rank list:%s' % (str(used_items[i]),str(item)))\n",
    "        # if i<=20:\n",
    "        rec_item = [tid for tid in item if tid not in used_items[i]]\n",
    "        # print(rec_item)\n",
    "        items.append(rec_item[:20])\n",
    "\n",
    "    def getMAP(N):\n",
    "        qarr = []\n",
    "        for i, uid in enumerate(users):\n",
    "            r = 0\n",
    "            drarr = []\n",
    "            for k in range(1, N+1):\n",
    "                intersect = set(items[i][:k]) & set(test_set[uid])\n",
    "                p = len(intersect) / k\n",
    "                newr = len(intersect) / len(set(test_set[uid]))\n",
    "                dr = (newr-r)*p\n",
    "                drarr.append(dr)\n",
    "                r = newr\n",
    "            qarr.append(np.sum(drarr))\n",
    "        return np.sum(qarr)/len(qarr)\n",
    "     \n",
    "    def res_at_k(k):\n",
    "        suc_methods = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        proj_suc = defaultdict(list)\n",
    "        proj_pre = defaultdict(list)\n",
    "        proj_recall = defaultdict(list)\n",
    "\n",
    "        for i, uid in enumerate(users):\n",
    "            pid = dataset.test_user2proj[uid]\n",
    "            intersect = set(items[i][:k]) & set(test_set[uid])\n",
    "            if len(intersect) > 0:\n",
    "                suc_methods.append(uid)\n",
    "                proj_suc[pid].append(1)\n",
    "            else:\n",
    "                logger.debug('failed uid %d' % uid)\n",
    "                logger.debug('GT:{}, REC:{}'.format(test_set[uid], items[i]))\n",
    "                proj_suc[pid].append(0)\n",
    "            p = len(intersect) / k\n",
    "            r = len(intersect) / len(set(test_set[uid]))\n",
    "            precisions.append(p)\n",
    "            recalls.append(r)\n",
    "            proj_pre[pid].append(p)\n",
    "            proj_recall[pid].append(r)\n",
    "        suc_rate = len(suc_methods) / len(users)\n",
    "        logger.info('----------------------result@%d--------------------------' % k)\n",
    "        logger.info('success rate at method level %f' % (suc_rate))\n",
    "        logger.info('mean precision:%f, mean recall:%f' % (np.mean(precisions), np.mean(recalls)))\n",
    "\n",
    "        suc_project = [np.mean(val) for val in proj_suc.values()]\n",
    "        pres = [np.mean(val) for val in proj_pre.values()]\n",
    "        recs = [np.mean(val) for val in proj_recall.values()]\n",
    "        logger.info('**********************************************************')\n",
    "        logger.info('success rate at project level %f' % (np.mean(np.mean(suc_project))))\n",
    "        logger.info('mean precision:%f, mean recall:%f' % (np.mean(pres), np.mean(recs)))\n",
    "        return suc_rate, np.mean(precisions), np.mean(recalls),np.mean(np.mean(suc_project)),np.mean(pres), np.mean(recs)\n",
    "\n",
    "    t2 = time.time()\n",
    "    logger.info('test end time: {}s'.format(t2 - t1))\n",
    "    for i in range(1, 21):\n",
    "        suc, pre, rec, pro_suc, pro_pre, pro_rec = res_at_k(i)\n",
    "        if suc > best_suc[i]:\n",
    "            best_suc[i] = suc\n",
    "        if pre > best_pre[i]:\n",
    "            best_pre[i] = pre\n",
    "        if rec > best_recall[i]:\n",
    "            best_recall[i] = rec\n",
    "        logger.warning('method level => top %d : best suc %f, best pre %f,  best recall %f' % (i, best_suc[i], best_pre[i], best_recall[i]))\n",
    "\n",
    "        if pro_suc > pro_best_suc[i]:\n",
    "            pro_best_suc[i] = pro_suc\n",
    "        if pro_pre > pro_best_pre[i]:\n",
    "            pro_best_pre[i] = pro_pre\n",
    "        if pro_rec > pro_best_recall[i]:\n",
    "            pro_best_recall[i] = pro_rec\n",
    "        logger.warning('project level => top %d : best suc %f, best pre %f,  best recall %f' % (i, pro_best_suc[i], pro_best_pre[i], pro_best_recall[i]))\n",
    "\n",
    "    logger.info('MAP: %f' % (getMAP(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4442/4442 [00:00<00:00, 170676.97it/s]\n",
      "  2%|▏         | 106/4442 [00:00<00:04, 977.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from disk.\n",
      "total user methods:4442, test_proj:{129, 130, 4, 5, 7, 12, 16, 145, 18, 146, 150, 22, 152, 154, 159, 33, 37, 170, 44, 45, 177, 179, 180, 182, 183, 55, 185, 60, 61, 189, 74, 80, 83, 98, 106, 107, 111, 122, 123, 125}\n",
      "test set methods count:175, invocations:1407\n",
      "load train datas ...\n",
      "train set methods count:4442, invocation: 111099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4442/4442 [00:05<00:00, 787.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_my_new_adj_matrix finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_mydata(datasetname)\n",
    "data.split_data(test_config)\n",
    "indexStr = ''\n",
    "test_set = data.test_dict\n",
    "users = np.asarray(list(test_set.keys()))\n",
    "test_user2proj = data.test_user2proj\n",
    "for uid in users:\n",
    "    indexStr = indexStr + 'project-' + str(test_user2proj[uid]) + ';method-' + str(uid) + ':' +str(data.invocation_mx[uid]) + '\\n'\n",
    "\n",
    "indexdir = './tmp/%s-testmethod.txt' % datasetname\n",
    "with open(indexdir, 'w') as f:\n",
    "    f.write(indexStr)\n",
    "    \n",
    "build_my_new_adj_matrix(data,data.train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:29<00:00,  5.93it/s]\n"
     ]
    }
   ],
   "source": [
    "myeval(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
